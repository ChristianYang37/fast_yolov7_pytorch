# Fast_Yolov7_PytorchğŸ‰ï¸ğŸ‰ï¸ğŸ‰ï¸

***<center>Build Your Faster Yolov7ğŸš€ï¸ </center>***

## Guide

* [Installation](#index1)
* [Quick Start](#index2)
* [Papers](#index3)
* [References](#index4)

## <a id="index1">Installation</a>ï¼š

```commandline
git clone https://github.com/ChristianYang37/fast_yolov7_pytorch.git
```

```commandline
pip install -r requirements.txt
```

If you can't install torch_pruning, please do as follow

```commandline
git clone https://github.com/VainF/Torch-Pruning.git
cd Torch-Pruning
python setup.py install
```

For pytorch yolov7 state dicts, [click here](https://github.com/WongKinYiu/yolov7#transfer-learning) to download.

## <a id="index2">Quick Start</a>ï¼š

### Pruning & Training

```commandline
python train.py --workers 8 --device 0 --batch-size 32 --data data/custom.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights 'yolov7_training.pt' --name yolov7-custom --hyp data/hyp.scratch.custom.yaml --sparsity 0.01 --num_epoch_to_prune 4 --prune_nore L2
```

if you want prune model without training, you can just set `epochs` = 0

#### Opts

`sparsity`: the sparsity of pruning

`num_epoch_to_prune`: prune model after `num_epoch_to_prune` times finetune

`prune_norm`: L1 or L2

#### Some Results

Prune `yolov7_training.pt` On COCO128.yaml (without finetune)


| Sparsity | Macs       | num_params | mAP@.5  | mAP@.0:.95 |
| -------- | ---------- | ---------- | ------- | ---------- |
| 0.005    | 6379356844 | 37115689   | 0.791   | 0.541      |
| 0.007    | 6373571463 | 37033908   | 0.783   | 0.515      |
| 0.01     | 6324846255 | 36735256   | 0.758   | 0.508      |
| 0.02     | 6187011754 | 35974768   | 0.615   | 0.38       |
| 0.05     | 5820065160 | 33891742   | 0.25    | 0.123      |
| 0.1      | 5237469860 | 30417686   | 0.00056 | 0.000102   |

So, for more efficient pruning, we suggest you set `--sparsity` 0.01 or 0.02, and set `--num_batch_to_prune` big enough to make sure the model has fitted the data before you prune it.

### Quantization

```commandline
python train.py --workers 8 --device 0 --batch-size 32 --data data/custom.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights 'yolov7_training.pt' --name yolov7-custom --hyp data/hyp.scratch.custom.yaml --method static
```

#### Opts

`method`: algorithm to quantify model, static or dynamic

`deploy_device`: pytorch now support x86 and arm, is enabled for `method` == static only

## <a id="index3">Papers</a>ï¼š

### å‰ªæ

#### ï¼ˆ1ï¼‰éç»“æ„å‰ªæ

ã€ŠDepGraph: Towards Any Structural Pruningã€‹

Link: [2301.12900.pdf (arxiv.org)](https://arxiv.org/pdf/2301.12900.pdf)

æ‘˜è¦ï¼šæå‡ºäº†ä¸€ç§é€šç”¨çš„å…¨è‡ªåŠ¨æ–¹æ³•â€”â€”ä¾èµ–å›¾(Dependency Graph, DepGraph)æ¥æ˜¾å¼åœ°å¯¹å±‚é—´çš„ç›¸äº’ä¾èµ–è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å¯¹è€¦åˆå‚æ•°è¿›è¡Œç»¼åˆåˆ†ç»„ã€‚

Github: [WongKinYiu/yolov7: Implementation of paper - YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (github.com)](https://github.com/WongKinYiu/yolov7)

ã€ŠNetwork Pruning via Transformable Architecture Searchã€‹

Link: [1905.09717v5.pdf (arxiv.org)](https://arxiv.org/pdf/1905.09717v5.pdf)

æ‘˜è¦ï¼šå¯¹äºæ¯ä¸€å±‚ç½‘ç»œåˆ†åŒ–å‡ºå¤šä¸ªåŒç±»çš„è¾ƒå°ç½‘ç»œï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦è®©é¢„å¤‡ç½‘ç»œç»“æ„å­¦ä¹ åŸç½‘ç»œçš„ç‰¹å¾å›¾è¡¨ç¤ºï¼Œé€‰å‡ºæŸè€—æœ€å°çš„ç½‘ç»œæ›¿æ¢åŸç½‘ç»œå±‚ã€‚

Github: [D-X-Y/AutoDL-Projects: Automated deep learning algorithms implemented in PyTorch. (github.com)](https://github.com/D-X-Y/AutoDL-Projects)

#### ï¼ˆ2ï¼‰ç»“æ„å‰ªæ

ã€ŠStructured Pruning for Deep Convolutional Neural Networks: A surveyã€‹

Link: [2303.00566v1.pdf (arxiv.org)](https://arxiv.org/pdf/2303.00566v1.pdf)

æ‘˜è¦ï¼šä»è¿‡æ»¤å™¨æ’åºæ–¹æ³•ã€æ­£åˆ™åŒ–æ–¹æ³•ã€åŠ¨æ€æ‰§è¡Œã€ç¥ç»ç»“æ„æœç´¢ã€å½©ç¥¨å‡è®¾å’Œå‰ªæçš„åº”ç”¨ç­‰æ–¹é¢å¯¹ç›®å‰æœ€å…ˆè¿›çš„ç»“æ„åŒ–å‰ªææŠ€æœ¯è¿›è¡Œäº†æ€»ç»“å’Œæ¯”è¾ƒã€‚ï¼ˆç»¼è¿°ï¼‰

Github: [he-y/Awesome-Pruning: A curated list of neural network pruning resources. (github.com)](https://github.com/he-y/Awesome-Pruning)

ã€ŠMovement Pruning: Adaptive Sparsity by Fine-Tuningã€‹

Link: [2005.07683v2.pdf (arxiv.org)](https://arxiv.org/pdf/2005.07683v2.pdf)

æ‘˜è¦ï¼šè¿åŠ¨å‰ªæï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿ç•™é‡è¦æ€§é«˜çš„è¿æ¥ï¼Œå³ä¿®å»ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸è¶‹äº0çš„è¿æ¥ï¼Œé€‚åˆç”¨æ¥å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿å‚æ•°ç¨€ç–åŒ–ã€‚

### é‡åŒ–

ã€ŠTRAINING WITH QUANTIZATION NOISE FOR EXTREME MODEL COMPRESSIONã€‹

Link: [2004.07320v3.pdf (arxiv.org)](https://arxiv.org/pdf/2004.07320v3.pdf)

æ‘˜è¦ï¼šé€šè¿‡åœ¨è®­ç»ƒä¸­å¼•å…¥éšæœºé‡åŒ–ã€éƒ¨åˆ†é‡åŒ–å¢å¼ºæ¨¡å‹å¯¹ç²¾åº¦æŸå¤±çš„é²æ£’æ€§ã€‚

ã€ŠLLM.int8(): 8-bit Matrix Multiplication for Transformers at Scaleã€‹

Link: [2208.07339v2.pdf (arxiv.org)](https://arxiv.org/pdf/2208.07339v2.pdf)

æ‘˜è¦ï¼šå¯¹çŸ©é˜µä¹˜æ³•ä¸­çš„æ¯ä¸ªå†…ç§¯ä½¿ç”¨ç‹¬ç«‹çš„å½’ä¸€åŒ–å¸¸æ•°çš„çŸ¢é‡é‡åŒ–ï¼Œä»¥é‡åŒ–å¤§å¤šæ•°ç‰¹å¾ï¼Œé€šè¿‡å¯¹åˆ—å’Œè¡Œè§„èŒƒåŒ–å¸¸æ•°çš„å¤–ç§¯è¿›è¡Œåè§„èŒƒåŒ–å¤„ç†æ¥æ¢å¤çŸ©é˜µä¹˜æ³•çš„è¾“å‡ºï¼Œæ•ˆæœè¿‘ä¹æ— æŸã€‚

## <a id="index4">References</a>:

1. [WongKinYiu/yolov7: Implementation of paper - YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (github.com)](https://github.com/WongKinYiu/yolov7)
2. [VainF/Torch-Pruning: [CVPR-2023] Towards Any Structural Pruning; LLaMA / CNNs / Transformers (github.com)](https://github.com/VainF/Torch-Pruning)
3. [PyTorch](https://pytorch.org/)
